{
 "metadata": {
  "name": "",
  "signature": "sha256:ef1a3fae6be9bad2e460d24a0fcde080d7c5a1958f020f0e5c46ce92210d2913"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Hadoop Bindings in Python\n",
      "\n",
      "TOC:\n",
      "\n",
      "   * IPython and shell integration\n",
      "   * Operate Hadoop from IPython Notebook\n",
      "   * One Python binding for Hadoop: https://github.com/Yelp/mrjob\n",
      "   * Review of HW1 in the unified environment of IPython Notebook\n",
      "\n",
      "## Preparation\n",
      "\n",
      "Setup your Hadoop PATHs.\n",
      "Put the following in your `~/.bashrc` file.\n",
      "Those environment variables will be setup every time you login.\n",
      "\n",
      "```\n",
      "export HADOOP_PREFIX=/home/azureuser/hadoop\n",
      "export HADOOP_HOME=/home/azureuser/hadoop\n",
      "export JAVA_HOME=/usr/lib/jvm/java-6-openjdk-amd64\n",
      "export PATH=$PATH:$HADOOP_PREFIX/bin\n",
      "export HADOOP_CONF_DIR=$HADOOP_PREFIX/conf\n",
      "```\n",
      "\n",
      "If your installation is not following [tutorial2](https://course.ie.cuhk.edu.hk/~engg4030/tutorial/tutorial2/), \n",
      "be sure to change accordingly.\n",
      "Note, although `HADOOP_HOME` is deprecated in newer Hadoop versions, `mrjob` relies on this variable.\n",
      "So we still set it here.\n",
      "\n",
      "Install `mrjob`\n",
      "\n",
      "```\n",
      "pip install --user mrjob \n",
      "```\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Shell in IPython\n",
      "\n",
      "The real magic of IPython's shell command integration is the ability to pass Python variables as input and collect output in Python variables."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Current folder\n",
      "!pwd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/azureuser\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# List files\n",
      "!ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data\t\t     hadooptmp\tPython-Hadoop.ipynb  wordcount_classes\r\n",
        "hadoop\t\t     largefile\treducer.py\t     wordcount.jar\r\n",
        "hadoop-1.0.3.tar.gz  mapper.py\tShakespeare.tar.gz   WordCount.java\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Collect shell command result in python variable\n",
      "files = !ls -1\n",
      "print len(files)\n",
      "# Use them in the Python style\n",
      "print files[0:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12\n",
        "['data', 'hadoop', 'hadoop-1.0.3.tar.gz']\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Pass python variables to shell commands\n",
      "first_file = files[0]\n",
      "!ls -l $first_file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total 6824\r\n",
        "-rw-rw---- 1 azureuser azureuser 141248 Sep 20  2012 play-12night.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 164154 Sep 20  2012 play-allswell.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 193944 Sep 20  2012 play-antonycleo.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 149978 Sep 20  2012 play-asyoulikeit.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 106757 Sep 20  2012 play-comedyerrors.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 207491 Sep 20  2012 play-coriolanus.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 199342 Sep 20  2012 play-cymbeline.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 216160 Sep 20  2012 play-hamlet.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 173445 Sep 20  2012 play-henry4p1.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 183449 Sep 20  2012 play-henry4p2.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 187193 Sep 20  2012 play-henry5.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 167137 Sep 20  2012 play-henry6p1.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 187263 Sep 20  2012 play-henry6p2.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 184858 Sep 20  2012 play-henry6p3.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 177991 Sep 20  2012 play-henry8.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 141425 Sep 20  2012 play-juliuscaesar.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 147219 Sep 20  2012 play-kingjohn.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 191623 Sep 20  2012 play-kinglear.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 154825 Sep 20  2012 play-loveslabours.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 130106 Sep 20  2012 play-macbeth.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 154966 Sep 20  2012 play-measure.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 147513 Sep 20  2012 play-merchantvenice.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 158544 Sep 20  2012 play-merrywives.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 114608 Sep 20  2012 play-midsummer.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 147403 Sep 20  2012 play-muchado.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 186767 Sep 20  2012 play-othello.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 136300 Sep 20  2012 play-pericles.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 160070 Sep 20  2012 play-richard2.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 219560 Sep 20  2012 play-richard3.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 174008 Sep 20  2012 play-romeojuliet.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 148077 Sep 20  2012 play-tamingshrew.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 118761 Sep 20  2012 play-tempest.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 134102 Sep 20  2012 play-timonathens.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 146589 Sep 20  2012 play-titus.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 191516 Sep 20  2012 play-troilus.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 124318 Sep 20  2012 play-twogents.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 173741 Sep 20  2012 play-winterstale.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser  20404 Sep 20  2012 poem-loverscomplaint.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser  27336 Sep 20  2012 poem-passionatepilgrim.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   3956 Sep 20  2012 poem-phoenixturtle.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser 117684 Sep 20  2012 poem-rapelucrece.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser  75338 Sep 20  2012 poem-venusadonis.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1128 Sep 20  2012 sonnet-100.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1112 Sep 20  2012 sonnet-101.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1135 Sep 20  2012 sonnet-102.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1115 Sep 20  2012 sonnet-103.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1139 Sep 20  2012 sonnet-104.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1116 Sep 20  2012 sonnet-105.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1116 Sep 20  2012 sonnet-106.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1133 Sep 20  2012 sonnet-107.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1124 Sep 20  2012 sonnet-108.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1114 Sep 20  2012 sonnet-109.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1128 Sep 20  2012 sonnet-10.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1121 Sep 20  2012 sonnet-110.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1115 Sep 20  2012 sonnet-111.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1117 Sep 20  2012 sonnet-112.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1123 Sep 20  2012 sonnet-113.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1125 Sep 20  2012 sonnet-114.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1138 Sep 20  2012 sonnet-115.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1109 Sep 20  2012 sonnet-116.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1116 Sep 20  2012 sonnet-117.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1127 Sep 20  2012 sonnet-118.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1126 Sep 20  2012 sonnet-119.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1153 Sep 20  2012 sonnet-11.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1124 Sep 20  2012 sonnet-120.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1126 Sep 20  2012 sonnet-121.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1103 Sep 20  2012 sonnet-122.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1119 Sep 20  2012 sonnet-123.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1127 Sep 20  2012 sonnet-124.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1112 Sep 20  2012 sonnet-125.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1097 Sep 20  2012 sonnet-126.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1128 Sep 20  2012 sonnet-127.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1129 Sep 20  2012 sonnet-128.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1115 Sep 20  2012 sonnet-129.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1130 Sep 20  2012 sonnet-12.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1124 Sep 20  2012 sonnet-130.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1126 Sep 20  2012 sonnet-131.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1118 Sep 20  2012 sonnet-132.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1131 Sep 20  2012 sonnet-133.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1114 Sep 20  2012 sonnet-134.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1123 Sep 20  2012 sonnet-135.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1133 Sep 20  2012 sonnet-136.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1138 Sep 20  2012 sonnet-137.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1130 Sep 20  2012 sonnet-138.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1135 Sep 20  2012 sonnet-139.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1120 Sep 20  2012 sonnet-13.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1128 Sep 20  2012 sonnet-140.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1126 Sep 20  2012 sonnet-141.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1122 Sep 20  2012 sonnet-142.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1134 Sep 20  2012 sonnet-143.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1105 Sep 20  2012 sonnet-144.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1073 Sep 20  2012 sonnet-145.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1132 Sep 20  2012 sonnet-146.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1116 Sep 20  2012 sonnet-147.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1135 Sep 20  2012 sonnet-148.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1108 Sep 20  2012 sonnet-149.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1112 Sep 20  2012 sonnet-14.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1121 Sep 20  2012 sonnet-150.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1121 Sep 20  2012 sonnet-151.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1134 Sep 20  2012 sonnet-152.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1125 Sep 20  2012 sonnet-153.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1116 Sep 20  2012 sonnet-154.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1126 Sep 20  2012 sonnet-15.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1118 Sep 20  2012 sonnet-16.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1140 Sep 20  2012 sonnet-17.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1130 Sep 20  2012 sonnet-18.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1134 Sep 20  2012 sonnet-19.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1122 Sep 20  2012 sonnet-1.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1143 Sep 20  2012 sonnet-20.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1123 Sep 20  2012 sonnet-21.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1117 Sep 20  2012 sonnet-22.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1126 Sep 20  2012 sonnet-23.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1139 Sep 20  2012 sonnet-24.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1111 Se"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "p 20  2012 sonnet-25.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1118 Sep 20  2012 sonnet-26.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1113 Sep 20  2012 sonnet-27.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1137 Sep 20  2012 sonnet-28.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1133 Sep 20  2012 sonnet-29.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1133 Sep 20  2012 sonnet-2.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1123 Sep 20  2012 sonnet-30.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1117 Sep 20  2012 sonnet-31.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1135 Sep 20  2012 sonnet-32.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1127 Sep 20  2012 sonnet-33.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1135 Sep 20  2012 sonnet-34.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1112 Sep 20  2012 sonnet-35.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1117 Sep 20  2012 sonnet-36.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1113 Sep 20  2012 sonnet-37.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1129 Sep 20  2012 sonnet-38.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1125 Sep 20  2012 sonnet-39.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1123 Sep 20  2012 sonnet-3.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1136 Sep 20  2012 sonnet-40.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1120 Sep 20  2012 sonnet-41.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1133 Sep 20  2012 sonnet-42.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1140 Sep 20  2012 sonnet-43.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1132 Sep 20  2012 sonnet-44.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1115 Sep 20  2012 sonnet-45.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1121 Sep 20  2012 sonnet-46.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1130 Sep 20  2012 sonnet-47.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1124 Sep 20  2012 sonnet-48.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1121 Sep 20  2012 sonnet-49.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1113 Sep 20  2012 sonnet-4.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1117 Sep 20  2012 sonnet-50.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1130 Sep 20  2012 sonnet-51.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1121 Sep 20  2012 sonnet-52.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1112 Sep 20  2012 sonnet-53.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1127 Sep 20  2012 sonnet-54.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1124 Sep 20  2012 sonnet-55.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1129 Sep 20  2012 sonnet-56.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1124 Sep 20  2012 sonnet-57.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1123 Sep 20  2012 sonnet-58.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1111 Sep 20  2012 sonnet-59.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1127 Sep 20  2012 sonnet-5.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1124 Sep 20  2012 sonnet-60.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1117 Sep 20  2012 sonnet-61.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1102 Sep 20  2012 sonnet-62.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1126 Sep 20  2012 sonnet-63.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1118 Sep 20  2012 sonnet-64.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1133 Sep 20  2012 sonnet-65.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1103 Sep 20  2012 sonnet-66.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1113 Sep 20  2012 sonnet-67.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1107 Sep 20  2012 sonnet-68.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1152 Sep 20  2012 sonnet-69.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1122 Sep 20  2012 sonnet-6.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1123 Sep 20  2012 sonnet-70.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1114 Sep 20  2012 sonnet-71.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1119 Sep 20  2012 sonnet-72.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1139 Sep 20  2012 sonnet-73.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1114 Sep 20  2012 sonnet-74.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1114 Sep 20  2012 sonnet-75.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1109 Sep 20  2012 sonnet-76.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1128 Sep 20  2012 sonnet-77.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1103 Sep 20  2012 sonnet-78.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1113 Sep 20  2012 sonnet-79.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1110 Sep 20  2012 sonnet-7.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1115 Sep 20  2012 sonnet-80.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1133 Sep 20  2012 sonnet-81.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1122 Sep 20  2012 sonnet-82.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1121 Sep 20  2012 sonnet-83.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1124 Sep 20  2012 sonnet-84.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1138 Sep 20  2012 sonnet-85.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1121 Sep 20  2012 sonnet-86.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1134 Sep 20  2012 sonnet-87.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1115 Sep 20  2012 sonnet-88.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1121 Sep 20  2012 sonnet-89.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1141 Sep 20  2012 sonnet-8.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1123 Sep 20  2012 sonnet-90.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1133 Sep 20  2012 sonnet-91.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1110 Sep 20  2012 sonnet-92.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1133 Sep 20  2012 sonnet-93.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1123 Sep 20  2012 sonnet-94.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1125 Sep 20  2012 sonnet-95.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1131 Sep 20  2012 sonnet-96.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1124 Sep 20  2012 sonnet-97.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1126 Sep 20  2012 sonnet-98.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1188 Sep 20  2012 sonnet-99.txt\r\n",
        "-rw-rw---- 1 azureuser azureuser   1127 Sep 20  2012 sonnet-9.txt\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Hadoop CLI from IPython Notebook\n",
      "\n",
      "There is no further magic as long as you understand Hadoop CLI and IPython's shell magic separately."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!hadoop"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Usage: hadoop [--config confdir] COMMAND\r\n",
        "where COMMAND is one of:\r\n",
        "  namenode -format     format the DFS filesystem\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  secondarynamenode    run the DFS secondary namenode\r\n",
        "  namenode             run the DFS namenode\r\n",
        "  datanode             run a DFS datanode\r\n",
        "  dfsadmin             run a DFS admin client\r\n",
        "  mradmin              run a Map-Reduce admin client\r\n",
        "  fsck                 run a DFS filesystem checking utility\r\n",
        "  fs                   run a generic filesystem user client\r\n",
        "  balancer             run a cluster balancing utility\r\n",
        "  fetchdt              fetch a delegation token from the NameNode\r\n",
        "  jobtracker           run the MapReduce job Tracker node\r\n",
        "  pipes                run a Pipes job\r\n",
        "  tasktracker          run a MapReduce task Tracker node\r\n",
        "  historyserver        run job history servers as a standalone daemon\r\n",
        "  job                  manipulate MapReduce jobs\r\n",
        "  queue                get information regarding JobQueues\r\n",
        "  version              print the version\r\n",
        "  jar <jar>            run a jar file\r\n",
        "  distcp <srcurl> <desturl> copy file or directories recursively\r\n",
        "  archive -archiveName NAME -p <parent path> <src>* <dest> create a hadoop archive\r\n",
        "  classpath            prints the class path needed to get the\r\n",
        "                       Hadoop jar and the required libraries\r\n",
        "  daemonlog            get/set the log level for each daemon\r\n",
        " or\r\n",
        "  CLASSNAME            run the class named CLASSNAME\r\n",
        "Most commands print help when invoked w/o parameters.\r\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!hadoop dfs -ls /"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 2 items\r\n",
        "drwxr-xr-x   - azureuser supergroup          0 2014-09-23 11:27 /home\r\n",
        "drwxr-xr-x   - azureuser supergroup          0 2014-09-25 15:01 /user\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's build a shortcut\n",
      "DFSCMD = 'hadoop dfs'\n",
      "!$DFSCMD -ls "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 2 items\r\n",
        "-rw-r--r--   3 azureuser supergroup    6460189 2014-09-30 03:43 /user/azureuser/largefile\r\n",
        "drwxr-xr-x   - azureuser supergroup          0 2014-09-30 10:51 /user/azureuser/output\r\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Delete output dir I created before.\n",
      "# Note, you may not have this file.\n",
      "!$DFSCMD -rmr 'output'\n",
      "!$DFSCMD -ls "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Deleted hdfs://10.62.154.63:9000/user/azureuser/output"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 1 items\r\n",
        "-rw-r--r--   3 azureuser supergroup    6460189 2014-09-30 03:43 /user/azureuser/largefile\r\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run a MapReduce job on hadoop\n",
      "!hadoop jar /home/azureuser/hadoop/hadoop-examples-1.0.3.jar wordcount largefile/ largefile.out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:21:22 INFO input.FileInputFormat: Total input paths to process : 1\r\n",
        "14/10/13 15:21:22 INFO util.NativeCodeLoader: Loaded the native-hadoop library\r\n",
        "14/10/13 15:21:22 WARN snappy.LoadSnappy: Snappy native library not loaded\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:21:22 INFO mapred.JobClient: Running job: job_201409251520_0010\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:21:23 INFO mapred.JobClient:  map 0% reduce 0%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:21:56 INFO mapred.JobClient:  map 100% reduce 0%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:22:14 INFO mapred.JobClient:  map 100% reduce 100%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:22:19 INFO mapred.JobClient: Job complete: job_201409251520_0010\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:22:19 INFO mapred.JobClient: Counters: 29\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:   Job Counters \r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Launched reduce tasks=1\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     SLOTS_MILLIS_MAPS=21031\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots (ms)=0\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots (ms)=0\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Launched map tasks=1\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Data-local map tasks=1\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     SLOTS_MILLIS_REDUCES=14091\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:   File Output Format Counters \r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Bytes Written=835072\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:   FileSystemCounters\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     FILE_BYTES_READ=2915846\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     HDFS_BYTES_READ=6460303\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=4073930\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=835072\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:   File Input Format Counters \r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Bytes Read=6460189\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:   Map-Reduce Framework\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Map output materialized bytes=1114723\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Map input records=165802\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Reduce shuffle bytes=0\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Spilled Records=268548\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Map output bytes=9577434\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     CPU time spent (ms)=10730\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Total committed heap usage (bytes)=265093120\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Combine input records=1127549\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     SPLIT_RAW_BYTES=114\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Reduce input records=72379\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Reduce input groups=72379\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Combine output records=196169\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Physical memory (bytes) snapshot=325742592\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Reduce output records=72379\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Virtual memory (bytes) snapshot=3125719040\r\n",
        "14/10/13 15:22:19 INFO mapred.JobClient:     Map output records=1003759\r\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Check the output\n",
      "!$DFSCMD -ls largefile.out\n",
      "# In order not to clustter the notebook,\n",
      "# we collect the results and only print part of them\n",
      "output = !$DFSCMD -tail largefile.out/part-r-00000\n",
      "print '\\n'.join(output[-5:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 3 items\r\n",
        "-rw-r--r--   3 azureuser supergroup          0 2014-10-13 15:22 /user/azureuser/largefile.out/_SUCCESS\r\n",
        "drwxr-xr-x   - azureuser supergroup          0 2014-10-13 15:21 /user/azureuser/largefile.out/_logs\r\n",
        "-rw-r--r--   3 azureuser supergroup     835072 2014-10-13 15:22 /user/azureuser/largefile.out/part-r-00000\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u2014send\t1\n",
        "\u2014thou\t1\n",
        "\u2014what\t1\n",
        "\u2014with\t1\n",
        "\u2022\t74\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!hadoop jar $HADOOP_PREFIX/contrib/streaming/hadoop-streaming-1.0.3.jar -mapper cat -reducer wc -input largefile -output largefile.out2\n",
      "# Had better use:\n",
      "# !hadoop jar $$HADOOP_PREFIX/contrib/streaming/hadoop-streaming-1.0.3.jar -mapper cat -reducer wc -input /bigfile -output /bigfile.out2\n",
      "# This is because \"$\" was interpolated in Python.\n",
      "# To avoid possible pollution from current working space, we use \"$$\" to escape the $-sign."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "packageJobJar: [/home/azureuser/hadooptmp/hadoop-unjar4691326296498418245/] [] /tmp/streamjob3609909016817848413.jar tmpDir=null\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:25:28 INFO util.NativeCodeLoader: Loaded the native-hadoop library"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "14/10/13 15:25:28 WARN snappy.LoadSnappy: Snappy native library not loaded\r\n",
        "14/10/13 15:25:28 INFO mapred.FileInputFormat: Total input paths to process : 1\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:25:28 INFO streaming.StreamJob: getLocalDirs(): [/home/azureuser/hadooptmp/mapred/local]\r\n",
        "14/10/13 15:25:28 INFO streaming.StreamJob: Running job: job_201409251520_0011\r\n",
        "14/10/13 15:25:28 INFO streaming.StreamJob: To kill this job, run:\r\n",
        "14/10/13 15:25:28 INFO streaming.StreamJob: /home/azureuser/hadoop/libexec/../bin/hadoop job  -Dmapred.job.tracker=10.62.154.63:9001 -kill job_201409251520_0011\r\n",
        "14/10/13 15:25:28 INFO streaming.StreamJob: Tracking URL: http://10.62.154.63:50030/jobdetails.jsp?jobid=job_201409251520_0011\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:25:29 INFO streaming.StreamJob:  map 0%  reduce 0%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:25:44 INFO streaming.StreamJob:  map 100%  reduce 0%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:25:53 INFO streaming.StreamJob:  map 100%  reduce 33%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:25:59 INFO streaming.StreamJob:  map 100%  reduce 100%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:26:05 INFO streaming.StreamJob: Job complete: job_201409251520_0011\r\n",
        "14/10/13 15:26:05 INFO streaming.StreamJob: Output: largefile.out2\r\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The result of \"wc\" command on Hadoop\n",
      "!$DFSCMD -cat largefile.out2/part-00000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 165802 1003759 6625991\t\r\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's check by running a wc directly\n",
      "!$DFSCMD -cat largefile | wc \n",
      "!$DFSCMD -copyToLocal largefile largefile2\n",
      "!wc largefile2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 165802 1003759 6460189\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "copyToLocal: Target largefile2 already exists\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 165802 1003759 6460189 largefile2\r\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**EXERCISE**:\n",
      "Investigate what is the difference. And Why."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let programmably construct the Hadoop Streaming command-line\n",
      "def construct_streaming_options(mapper, reducer, input, output):\n",
      "    return ' '.join(['-mapper', mapper,\n",
      "                     '-reducer', reducer,\n",
      "                     '-input', input,\n",
      "                     '-output', output])\n",
      "    \n",
      "STREAMINGCMD = 'hadoop jar $HADOOP_PREFIX/contrib/streaming/hadoop-streaming-1.0.3.jar'\n",
      "options = construct_streaming_options('cat', 'wc', 'largefile', 'largefile.out3')\n",
      "print 'STREAMINGCMD:', STREAMINGCMD\n",
      "print 'options:', options\n",
      "!$STREAMINGCMD $options\n",
      "!$DFSCMD -ls largefile.out3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "STREAMINGCMD: hadoop jar $HADOOP_PREFIX/contrib/streaming/hadoop-streaming-1.0.3.jar\n",
        "options: -mapper cat -reducer wc -input largefile -output largefile.out3\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "packageJobJar: [/home/azureuser/hadooptmp/hadoop-unjar1070224149882522530/] [] /tmp/streamjob6941772224846745313.jar tmpDir=null\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:43:31 INFO util.NativeCodeLoader: Loaded the native-hadoop library\r\n",
        "14/10/13 15:43:31 WARN snappy.LoadSnappy: Snappy native library not loaded\r\n",
        "14/10/13 15:43:31 INFO mapred.FileInputFormat: Total input paths to process : 1\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:43:31 INFO streaming.StreamJob: getLocalDirs(): [/home/azureuser/hadooptmp/mapred/local]\r\n",
        "14/10/13 15:43:31 INFO streaming.StreamJob: Running job: job_201409251520_0012\r\n",
        "14/10/13 15:43:31 INFO streaming.StreamJob: To kill this job, run:\r\n",
        "14/10/13 15:43:31 INFO streaming.StreamJob: /home/azureuser/hadoop/libexec/../bin/hadoop job  -Dmapred.job.tracker=10.62.154.63:9001 -kill job_201409251520_0012\r\n",
        "14/10/13 15:43:31 INFO streaming.StreamJob: Tracking URL: http://10.62.154.63:50030/jobdetails.jsp?jobid=job_201409251520_0012\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:43:32 INFO streaming.StreamJob:  map 0%  reduce 0%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:43:50 INFO streaming.StreamJob:  map 100%  reduce 0%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:43:59 INFO streaming.StreamJob:  map 100%  reduce 33%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:44:05 INFO streaming.StreamJob:  map 100%  reduce 100%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14/10/13 15:44:11 INFO streaming.StreamJob: Job complete: job_201409251520_0012\r\n",
        "14/10/13 15:44:11 INFO streaming.StreamJob: Output: largefile.out3\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 3 items\r\n",
        "-rw-r--r--   3 azureuser supergroup          0 2014-10-13 15:44 /user/azureuser/largefile.out3/_SUCCESS\r\n",
        "drwxr-xr-x   - azureuser supergroup          0 2014-10-13 15:43 /user/azureuser/largefile.out3/_logs\r\n",
        "-rw-r--r--   3 azureuser supergroup         25 2014-10-13 15:43 /user/azureuser/largefile.out3/part-00000\r\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## MRJob\n",
      "\n",
      "`mrjob` is well documented.\n",
      "See the docs for more information: http://mrjob.readthedocs.org/en/latest/\n",
      "\n",
      "To get started, install with pip:\n",
      "```\n",
      "sudo pip install mrjob\n",
      "```\n",
      "\n",
      "The general workflow of `mrjob`:\n",
      "\n",
      "   * Write you job as a Python class, which provides `mapper`, `combiner` and `reducer`.\n",
      "   * `python myjob.py <input>` to test it locally.\n",
      "   * `python myjob.py -r hadoop <input>` to run on Hadoop.\n",
      "   * `python myjob.py -r hadoop hdfs://path/to/your/input/ --output-dir hdfs://path/to/your/output/` \n",
      "   to use files HDFS.\n",
      "   \n",
      "`mrjob` wraps Hadoop Streaming to take care of some I/O details.\n",
      "So the code is very concise, looking like pseudo-code.\n",
      "It's easy to programmably construct `mrjob` command lines.\n",
      "Just refer to the above streaming example.\n",
      "Since `mrjob` provides its own runner, we demonstrate it in the following cells.\n",
      "\n",
      "**NOTE**:\n",
      "The interface is in a generator style.\n",
      "[further read](http://www.dabeaz.com/generators/index.html)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file wordcountjob.py\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "\n",
      "WORD_RE = re.compile(r\"[\\w']+\")\n",
      "\n",
      "class MRWordFreqCount(MRJob):\n",
      "\n",
      "    def mapper(self, _, line):\n",
      "        for word in WORD_RE.findall(line):\n",
      "            yield (word.lower(), 1)\n",
      "\n",
      "    def combiner(self, word, counts):\n",
      "        yield (word, sum(counts))\n",
      "\n",
      "    def reducer(self, word, counts):\n",
      "        yield (word, sum(counts))\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    MRWordFreqCount.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting wordcountjob.py\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Note the above \"%%file\" magic will really write this file when executed.\n",
      "# Be careful not to override your work..\n",
      "!ls -l wordcountjob.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rw-rw-r-- 1 azureuser azureuser 411 Oct 13 15:52 wordcountjob.py\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from wordcountjob import MRWordFreqCount\n",
      "job = MRWordFreqCount(args=['-r', 'hadoop',                         # Specify \"hadoop\" as the backend\n",
      "                                                                    #     (Can be \"local\" or \"emr\")\n",
      "                            'hdfs:///user/azureuser/largefile',                      # Equivalent to -input option of Hadoop Streaming\n",
      "                                                                    #     (Can be a local path)\n",
      "                            '--output-dir', 'hdfs:///user/azureuser/largefile.out4', # Equivalent to -output option of Hadoop Streaming\n",
      "                                                                    #     (Can be a local path)\n",
      "                            '--no-output'])\n",
      "runner = job.make_runner()\n",
      "runner.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines = runner.stream_output()\n",
      "# Just show you some example output\n",
      "print lines.next()\n",
      "print lines.next()\n",
      "print lines.next()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"'\"\t1182\n",
        "\n",
        "\"'a\"\t89\n",
        "\n",
        "\"'a'\"\t1\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Post-processing of the MapReduce Job\n",
      "\n",
      "Let's re-do some of the problems from [homework1](https://course.ie.cuhk.edu.hk/~engg4030/homework/).\n",
      "You will get a feel of the integrated working environment we gradually build up during this semester."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the output and sort.\n",
      "lines = runner.stream_output()\n",
      "sorted_lines = sorted(lines, key=lambda x: int(x.split('\\t')[1]), reverse=True)\n",
      "sorted_lines[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "['\"i\"\\t904\\n', '\"the\"\\t869\\n', '\"and\"\\t818\\n', '\"to\"\\t663\\n', '\"of\"\\t640\\n']"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note, for demo purpose, we sort inside this notebook. In practice (for big data set),\n",
      "\n",
      "   * You may want to sort in Hadoop \n",
      "   and load part of it in IPython Notebook for post-processing/ visualization\n",
      "   * Even if you want to sort locally, partial sort via heap can be a better choice\n",
      "   ( `heapq.nlargest` used in [tutorial10](https://course.ie.cuhk.edu.hk/~engg4030/tutorial/tutorial10/) )"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_to_plot = 20\n",
      "labels = map(lambda x: x.split('\\t')[0], sorted_lines[:num_to_plot])\n",
      "counts = map(lambda x: int(x.split('\\t')[1]), sorted_lines[:num_to_plot])\n",
      "bar(range(len(counts)), counts)\n",
      "xticks(range(len(counts)), labels, rotation=90)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "([<matplotlib.axis.XTick at 0x4847fd0>,\n",
        "  <matplotlib.axis.XTick at 0x4847e90>,\n",
        "  <matplotlib.axis.XTick at 0x40eb110>,\n",
        "  <matplotlib.axis.XTick at 0x40eb710>,\n",
        "  <matplotlib.axis.XTick at 0x40ebd90>,\n",
        "  <matplotlib.axis.XTick at 0x40e5450>,\n",
        "  <matplotlib.axis.XTick at 0x45dc890>,\n",
        "  <matplotlib.axis.XTick at 0x45c4190>,\n",
        "  <matplotlib.axis.XTick at 0x45c4810>,\n",
        "  <matplotlib.axis.XTick at 0x45c4e90>,\n",
        "  <matplotlib.axis.XTick at 0x45bb550>,\n",
        "  <matplotlib.axis.XTick at 0x45bbbd0>,\n",
        "  <matplotlib.axis.XTick at 0x45d0290>,\n",
        "  <matplotlib.axis.XTick at 0x45d0910>,\n",
        "  <matplotlib.axis.XTick at 0x45d0f90>,\n",
        "  <matplotlib.axis.XTick at 0x45b9650>,\n",
        "  <matplotlib.axis.XTick at 0x45b9cd0>,\n",
        "  <matplotlib.axis.XTick at 0x4a3f390>,\n",
        "  <matplotlib.axis.XTick at 0x4a3fa10>,\n",
        "  <matplotlib.axis.XTick at 0x4a420d0>],\n",
        " <a list of 20 Text xticklabel objects>)"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAETCAYAAAA8rh0/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+tEAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x48495d0>"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Cut the reference to runner and wait for Garbage Collection.\n",
      "# The destructor of runner will called to cleanup resources.\n",
      "del runner"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A better pattern to ensure resource is returned is the `with` statement.\n",
      "\n",
      "```\n",
      "with job.make_runner() as runner:\n",
      "    runner.run()\n",
      "    # Do other things with runner, e.g. get output\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**EXERCISE**:\n",
      "Try to construct your own convenient Hadoop workflow in IPython without other libraries like `mrjob`.\n",
      "\n",
      "   * You can use `%%file` magic to maintain mapper and reducer scripts.\n",
      "   * You can use Python string operation to construct the Hadoop CLI options.\n",
      "   * You can pass python variables to shell for the execution.\n",
      "\n",
      "**EXERCISE**:\n",
      "Try to compare other Python bindings in terms of execution efficiency and devlopement efficiency.\n",
      "See references for some pointers.\n",
      "\n",
      "## References\n",
      "\n",
      "   * A [blog post](http://blog.cloudera.com/blog/2013/01/a-guide-to-python-frameworks-for-hadoop/)\n",
      "   from Cloudera to compare different Python bindings.\n",
      "   [(code repo)](https://github.com/cloudera/python-ngrams).\n",
      "   [(examples)](https://github.com/Yelp/mrjob/tree/master/mrjob/examples)."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}
